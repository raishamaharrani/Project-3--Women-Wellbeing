{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox1p\n",
    "import pickle\n",
    "from os import path\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "import plotly.express as px \n",
    "#from plotnine import ggplot, aes, geom_line, geom_point, facet_wrap, theme\n",
    "import plotly.graph_objects as go\n",
    "# Machine learning algorithms and model evaluation\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# from skforecast.model_selection import backtesting_forecaster\n",
    "#from skforecast.model_selection import grid_search_forecaster\n",
    "#from skforecast.model_selection import bayesian_search_forecaster\n",
    "#from lightgbm import LGBMRegressor\n",
    "# Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Preprocessing:\n",
    "Load the datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the three datasets\n",
    "average_hours = pd.read_csv('Resources/average-usual-weekly-hours-worked-women-15-years-and-older.csv')\n",
    "employment_ratio = pd.read_csv(\"Resources/female-employment-to-population-ratio.csv\")\n",
    "wage_gap = pd.read_csv(\"Resources/gender-wage-gap-oecd.csv\")\n",
    "percapita_labor = pd.read_csv(\"Resources/female-labor-force-participation-rates-by-national-per-capita-income.csv\")\n",
    "school_years = pd.read_csv(\"Resources/mean-years-of-schooling-female.csv\")\n",
    "maternity_leave = pd.read_csv(\"Resources/paid-leave-at-least-14-weeks-mothers.csv\")\n",
    "labor_sector = pd.read_csv(\"Resources/share-of-female-workers-by-sector.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the Columns and Rows for each of the dataset \n",
    "print(f'Shape of average_hours DataFrame: {average_hours.shape}')\n",
    "print(f'Shape of employment_ratio DataFrame: {employment_ratio.shape}')\n",
    "print(f'Shape of wage_gap DataFrame: {wage_gap.shape}')\n",
    "print(f'Shape of percapita_labor DataFrame: {percapita_labor.shape}')\n",
    "print(f'Shape of school_years DataFrame: {school_years.shape}')\n",
    "print(f'Shape of maternity_leave DataFrame: {maternity_leave.shape}')\n",
    "print(f'Shape of labor_sector DataFrame: {labor_sector.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns to make it shorter\n",
    "average_hours = average_hours.rename(columns={'Average weekly hours worked (women, 15+) (OECD Labor Force Statistics (2017))': 'Avg_Hours_Worked'})\n",
    "employment_ratio = employment_ratio.rename(columns={'Employment to population ratio, 15+, female (%) (national estimate)': 'Emp_Pop_Ratio'})\n",
    "wage_gap = wage_gap.rename(columns={'Gender wage gap (OECD 2017)': 'Gender_Wage_Gap'})\n",
    "percapita_labor = percapita_labor.rename(columns={'Labor force participation rate, female (% of female population ages 15+) (modeled ILO estimate)': 'Labor_Force'})\n",
    "school_years = school_years.rename(columns={'Mean years of schooling (ISCED 1 or higher), population 25+ years, female': 'School_Years_Mean'})\n",
    "maternity_leave = maternity_leave.rename(columns={'Paid leave of at least 14 weeks available to mothers (1=yes; 0=no)': 'Paid_Leave'})\n",
    "labor_sector = labor_sector.rename(columns={'Female share of employment in agriculture (%)': 'Argiculture','Female share of employment in industry (%)': 'Industry','Female share of employment in services (%)': 'Services'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Null Values from these two datasets \n",
    "average_hours.dropna(inplace=True)\n",
    "employment_ratio.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the datasets\n",
    "merged_df= average_hours.merge(employment_ratio, on=['Entity', 'Code', 'Year'], how='outer')\n",
    "merged_df= merged_df .merge(wage_gap, on=['Entity', 'Code', 'Year'], how='outer')\n",
    "merged_df= merged_df .merge(percapita_labor, on=['Entity', 'Code', 'Year'], how='outer')\n",
    "merged_df= merged_df .merge(school_years, on=['Entity', 'Code', 'Year'], how='outer')\n",
    "merged_df= merged_df .merge(maternity_leave, on=['Entity', 'Code', 'Year'], how='outer')\n",
    "merged_df= merged_df .merge(labor_sector, on=['Entity', 'Code', 'Year'], how='outer')\n",
    "\n",
    "# Check the result\n",
    "print(merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values \n",
    "print(merged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop colum \"Continent\"\n",
    "merged_df = merged_df.drop(\"Continent\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = merged_df.duplicated().sum()\n",
    "print(f\"Number of duplicates: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows with less than <= 3 letters\n",
    "filtered_df = merged_df[merged_df['Code'].str.len()<=3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types of each column\n",
    "print(filtered_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform some basic EDA- View the dataset's distribution\n",
    "print(filtered_df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle Null Values using the KNNImputer. For KNNImputer can only work on numerical columns. \n",
    "First step is to define numerical and catrgorical columns and then train only on the numerical columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and catrgorical columns \n",
    "numerical_cols = ['Year', 'Avg_Hours_Worked', 'Emp_Pop_Ratio', 'Gender_Wage_Gap', \n",
    "                  'Labor_Force', 'GDP per capita, PPP (constant 2017 international $)', \n",
    "                  'School_Years_Mean', 'Paid_Leave', 'Argiculture', 'Industry', \n",
    "                  'Services']\n",
    "\n",
    "categorical_cols = ['Entity', 'Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the numerical columns with n_neighbor =5\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Impute null values in numerical columns using KNNImputer\n",
    "imputer_num = KNNImputer(n_neighbors=5)\n",
    "imputed_num_data = imputer_num.fit_transform(filtered_df[numerical_cols])\n",
    "\n",
    "# One-Hot Encode categorical columns\n",
    "#ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "#encoded_array = ohe.fit_transform(filtered_df[categorical_cols])\n",
    "#encoded_df = pd.DataFrame(encoded_array.toarray(), columns=ohe.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Concatenate imputed numerical columns with one-hot encoded categorical columns\n",
    "#df_encoded = pd.concat([pd.DataFrame(imputed_num_data, columns=numerical_cols), encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values before imputation\n",
    "print(\"Null values before imputation:\")\n",
    "print(filtered_df[numerical_cols].isnull().sum())\n",
    "\n",
    "#imputed_num_data = imputer_num.fit_transform(filtered_df[numerical_cols])\n",
    "\n",
    "# Check null values after the imputation \n",
    "imputed_num_df = pd.DataFrame(imputed_num_data, columns=numerical_cols)\n",
    "imputed_num_df.reset_index(inplace=True, drop=True)\n",
    "cat_df= filtered_df[categorical_cols]\n",
    "cat_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(cat_df.isnull().sum())\n",
    "print(\"Null values after imputation:\")\n",
    "print(imputed_num_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the KNNimputer was only used on the numerical columns, we have to use concate function to add the categorical columns to the imputed dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the imputed numerical columns with the original categorical columns\n",
    "# pd.DataFrame(imputed_num_data, columns=numerical_cols)\n",
    "imputed_df = pd.concat([imputed_num_df, cat_df], axis=1)\n",
    "#imputed_df[categorical_cols] = imputed_df[categorical_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the new datset\n",
    "imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values after concating the numerical and categorical columns\n",
    "print(imputed_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform basic EDA (Exploratory Data Analysis)\n",
    "Top 10 Countries for each of the features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 countries by Average Hours Worked  \n",
    "top_countries = imputed_df.groupby('Entity')['Avg_Hours_Worked'].mean().reset_index()\n",
    "top_countries = top_countries.nlargest(10, 'Avg_Hours_Worked')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(top_countries['Entity'], top_countries['Avg_Hours_Worked'])\n",
    "plt.title(\"Top 10 Countries by Avg_Hours_Worked\")\n",
    "plt.xlabel(\"Avg_Hours_Worked\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 countries by Emp_Pop_Ratio  \n",
    "top_countries = imputed_df.groupby('Entity')['Emp_Pop_Ratio'].mean().reset_index()\n",
    "top_countries = top_countries.nlargest(10, 'Emp_Pop_Ratio')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(top_countries['Entity'], top_countries['Emp_Pop_Ratio'])\n",
    "plt.title(\"Top 10 Countries by Emp_Pop_Ratio\")\n",
    "plt.xlabel(\"Emp_Pop_Ratio\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 countries by Gender_Wage_Gap\n",
    "top_countries = merged_df.groupby('Entity')['Gender_Wage_Gap'].mean().reset_index()\n",
    "top_countries = top_countries.nlargest(10, 'Gender_Wage_Gap')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(top_countries['Entity'], top_countries['Gender_Wage_Gap'])\n",
    "plt.title(\"Top 10 Countries by Gender_Wage_Gap\")\n",
    "plt.xlabel(\"Gender_Wage_Gap\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 countries by Argiculture\n",
    "top_countries = merged_df.groupby('Entity')['Argiculture'].mean().reset_index()\n",
    "top_countries = top_countries.nlargest(10, 'Argiculture')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(top_countries['Entity'], top_countries['Argiculture'])\n",
    "plt.title(\"Top 10 Countries Female share of employment in Agriculture\")\n",
    "plt.xlabel(\"Argiculture\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 countries by Industry\n",
    "top_countries = merged_df.groupby('Entity')['Industry'].mean().reset_index()\n",
    "top_countries = top_countries.nlargest(10, 'Industry')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(top_countries['Entity'], top_countries['Industry'])\n",
    "plt.title(\"Top 10 Countries by Female share of employment in industry\")\n",
    "plt.xlabel(\"Industry(%)\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 countries by Services\n",
    "top_countries = merged_df.groupby('Entity')['Services'].mean().reset_index()\n",
    "top_countries = top_countries.nlargest(10, 'Services')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(top_countries['Entity'], top_countries['Services'])\n",
    "plt.title(\"Top 10 Countries  by Female share of employment in services\")\n",
    "plt.xlabel(\"Services(%)\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BASIC EDA: Bottom 10 Countries for each of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the bottom 10 countries by average hours worked\n",
    "bottom_countries = merged_df.groupby('Entity')['Avg_Hours_Worked'].mean().reset_index()\n",
    "bottom_countries = bottom_countries.nsmallest(10, 'Avg_Hours_Worked')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(bottom_countries['Entity'], bottom_countries['Avg_Hours_Worked'])\n",
    "plt.title(\"Bottom 10 Countries by Average Hours Worked\")\n",
    "plt.xlabel(\"Average Hours Worked\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 countries by Services\n",
    "bottom_countries = merged_df.groupby('Entity')['Services'].mean().reset_index()\n",
    "bottom_countries = bottom_countries.nsmallest(10, 'Services')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(bottom_countries['Entity'], bottom_countries['Services'])\n",
    "plt.title(\"Bottom 10 Countries by Female in Services\")\n",
    "plt.xlabel(\"Services\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE A PROFESSIONAL WELLBEING SCORE 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns that will be used to create the professional wellbeing score\n",
    "columns_to_use = ['Avg_Hours_Worked', 'Emp_Pop_Ratio', 'Gender_Wage_Gap', \n",
    "                  'Labor_Force', 'GDP per capita, PPP (constant 2017 international $)', \n",
    "                  'School_Years_Mean', 'Paid_Leave', 'Argiculture', 'Industry', \n",
    "                  'Services']\n",
    "\n",
    "# Scale the columns using Min-Max Scaler to have values between 0 and 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "imputed_df[columns_to_use] = scaler.fit_transform(imputed_df[columns_to_use])\n",
    "\n",
    "# Calculate the professional wellbeing score as the average of the scaled columns\n",
    "imputed_df['Professional_Wellbeing_Score'] = imputed_df[columns_to_use].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "imputed_df[columns_to_use] = scaler.fit_transform(imputed_df[columns_to_use])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = imputed_df[columns_to_use]\n",
    "y = imputed_df['Professional_Wellbeing_Score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Development #1 \n",
    "Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the features and target\n",
    "# Replace with your feature columns columns_to_use = [...]  \n",
    "X = imputed_df[columns_to_use]\n",
    "y = imputed_df['Professional_Wellbeing_Score']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(10, 200, 10),\n",
    "    'max_depth': [None] + list(np.arange(1, 20, 2)),\n",
    "    'min_samples_split': np.arange(2, 10, 1),\n",
    "    'min_samples_leaf': np.arange(1, 10, 1),\n",
    "    'max_features': [1.0, 'sqrt', 'log2']  # Avoid using 'auto'\n",
    "}\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,  # Number of parameter settings sampled\n",
    "    cv=5,        # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1    # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best parameters found\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "\n",
    "# Predict using the best model\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Calculate and display the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model #1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model #2 Random Forest Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model #3 Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(\"Linear Regression:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_lr))\n",
    "print(\"R2:\", r2_score(y_test, y_pred_lr))\n",
    "\n",
    "print(\"\\nRandom Forest Regressor:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_rf))\n",
    "print(\"R2:\", r2_score(y_test, y_pred_rf))\n",
    "\n",
    "print(\"\\nGradient Boosting Regressor:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_gb))\n",
    "print(\"R2:\", r2_score(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(50, 251, 50),\n",
    "    'learning_rate': np.linspace(0.01, 0.2, 10),\n",
    "    'max_depth': np.arange(3, 8),\n",
    "    'min_samples_split': np.arange(2, 11),\n",
    "    'min_samples_leaf': np.arange(1, 11)\n",
    "}\n",
    "\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=gb_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "mse_best = mean_squared_error(y_test, y_pred_best)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"MSE:\", mse_best)\n",
    "print(\"R2:\", r2_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model #4 Neural Networks with relu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Define the input features (X) and the target variable (y)\n",
    "X = imputed_df[columns_to_use]\n",
    "y = imputed_df['Professional_Wellbeing_Score']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))  # Output layer with a single neuron\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Flatten y_pred and y_test to 1-dimensional arrays\n",
    "y_pred = y_pred.flatten()\n",
    "y_test = y_test.values.flatten()\n",
    "\n",
    "# Evaluate the model using Mean Squared Error (MSE)\n",
    "mse = np.mean((y_pred - y_test) ** 2)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Professional Wellbeing App using Gradio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def get_professional_wellbeing_score(entity_name):\n",
    "    # Search for the entity name in the dataset\n",
    "    entity_row = imputed_df[imputed_df[\"Entity\"] == entity_name]\n",
    "    if entity_row.empty:\n",
    "        print(f\"Entity '{entity_name}' not found in dataset\")\n",
    "        return \"Entity not found\"\n",
    "    else:\n",
    "        # Return the professional wellbeing score for the entity\n",
    "        print(f\"Entity '{entity_name}' found in dataset\")\n",
    "        return entity_row[\"Professional_Wellbeing_Score\"].values[0]\n",
    "\n",
    "# Create the Gradio app\n",
    "gr_interface = gr.Interface(\n",
    "    fn=get_professional_wellbeing_score,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Professional Wellbeing Score Lookup\",\n",
    "    description=\"Enter an entity name to get its professional wellbeing score\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "gr_interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Budiling the gradio app to work with LLM to provide explaination and suggestion for each country's professional wellbeing score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "# Define a function to explain the professional wellbeing score based on the features\n",
    "def explain_score(entity_name, features):\n",
    "    if not isinstance(entity_name, str):\n",
    "        raise ValueError(\"Entity name must be a string\")\n",
    "    if not isinstance(features, dict):\n",
    "        raise ValueError(\"Features must be a dictionary\")\n",
    "    required_keys = [\"Professional_Wellbeing_Score\"]\n",
    "    if not all(key in features for key in required_keys):\n",
    "        raise ValueError(\"Features must contain the required keys\")\n",
    "    \n",
    "    explanation = f\"Entity {entity_name} has a professional wellbeing score of {features['Professional_Wellbeing_Score']:.2f} due to the following factors:\\n\"\n",
    "    for feature, value in features.items():\n",
    "        if feature != \"Professional_Wellbeing_Score\":\n",
    "            if isinstance(value, (int, float)):\n",
    "                explanation += f\"- {feature.capitalize()}: {value:.2f}\\n\"\n",
    "            else:\n",
    "                explanation += f\"- {feature.capitalize()}: {value}\\n\"\n",
    "    return explanation\n",
    "\n",
    "# Define a function to generate suggestions and solutions to improve the score using the LLM model\n",
    "def generate_suggestions_and_solutions(entity_name, features):\n",
    "    prompt = f\"Entity {entity_name} has a professional wellbeing score of {features['Professional_Wellbeing_Score']:.2f}. Provide suggestions and solutions to improve it.\"\n",
    "    inputs = tokenizer.encode_plus(prompt, \n",
    "                                    add_special_tokens=True, \n",
    "                                    max_length=512, \n",
    "                                    return_attention_mask=True, \n",
    "                                    return_tensors='pt')\n",
    "    output = model.generate(inputs['input_ids'], \n",
    "                            attention_mask=inputs['attention_mask'], \n",
    "                            max_length=1024, \n",
    "                            early_stopping=True)\n",
    "    suggestions_and_solutions = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return suggestions_and_solutions\n",
    "\n",
    "# Load the pre-trained GPT-2 model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Test the functions\n",
    "entity_name = \"Entity 1\"\n",
    "features = imputed_df.loc[0, :]\n",
    "explanation = explain_score(entity_name, features)\n",
    "suggestions_and_solutions = generate_suggestions_and_solutions(entity_name, features)\n",
    "print(explanation)\n",
    "print(suggestions_and_solutions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
